{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-04T07:36:16.642013200Z",
     "start_time": "2025-07-04T07:36:16.627501200Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Network Architecture"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "class EmbeddingNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EmbeddingNet, self).__init__()\n",
    "        self.convnet = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 320x320\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 160x160\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 80x80\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 40x40\n",
    "\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "        self.fc = nn.Linear(512, 128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convnet(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)  # batch_size, 128)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-04T07:36:16.704688900Z",
     "start_time": "2025-07-04T07:36:16.642013200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "class TripletNet(nn.Module):\n",
    "    def __init__(self, embedding_net):\n",
    "        super(TripletNet, self).__init__()\n",
    "        self.embedding_net = embedding_net\n",
    "\n",
    "    def forward(self, anchor, positive, negative):\n",
    "        anchor_out = self.embedding_net(anchor)\n",
    "        positive_out = self.embedding_net(positive)\n",
    "        negative_out = self.embedding_net(negative)\n",
    "        return anchor_out, positive_out, negative_out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-04T07:36:16.704688900Z",
     "start_time": "2025-07-04T07:36:16.648649400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, anchor, positive, negative):\n",
    "        d_positive = F.pairwise_distance(anchor, positive, p=2)\n",
    "        d_negative = F.pairwise_distance(anchor, negative, p=2)\n",
    "        loss = F.relu(d_positive - d_negative + self.margin)\n",
    "        return loss.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-04T07:36:16.705690Z",
     "start_time": "2025-07-04T07:36:16.672110500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset Design"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "class ImageTripletDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.anchor_dir = os.path.join(root_dir, \"anchor\")\n",
    "        self.positive_dir = os.path.join(root_dir, \"positive\")\n",
    "        self.negative_dir = os.path.join(root_dir, \"negative\")\n",
    "\n",
    "        self.filenames = sorted(os.listdir(self.anchor_dir))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        anchor_path = os.path.join(self.anchor_dir, self.filenames[idx])\n",
    "        positive_path = os.path.join(self.positive_dir, self.filenames[idx])\n",
    "        negative_path = os.path.join(self.negative_dir, self.filenames[idx])\n",
    "\n",
    "        anchor = Image.open(anchor_path).convert(\"RGB\")\n",
    "        positive = Image.open(positive_path).convert(\"RGB\")\n",
    "        negative = Image.open(negative_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            anchor = self.transform(anchor)\n",
    "            positive = self.transform(positive)\n",
    "            negative = self.transform(negative)\n",
    "\n",
    "        return anchor, positive, negative"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-04T07:36:16.705690Z",
     "start_time": "2025-07-04T07:36:16.682674600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "    T.Resize((640, 640)),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "dataset = ImageTripletDataset(root_dir=\"triplet_data\", transform=transform)\n",
    "loader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-04T07:36:16.705690Z",
     "start_time": "2025-07-04T07:36:16.694199700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training Loop"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "embedding_net = EmbeddingNet()\n",
    "model = TripletNet(embedding_net).to(device)\n",
    "\n",
    "triplet_loss = nn.TripletMarginLoss(margin=1.0, p=2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-04T07:36:17.323972600Z",
     "start_time": "2025-07-04T07:36:16.703690200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/32] - Loss: 0.9991\n",
      "Epoch [2/32] - Loss: 0.9938\n",
      "Epoch [3/32] - Loss: 0.9852\n",
      "Epoch [4/32] - Loss: 0.9788\n",
      "Epoch [5/32] - Loss: 0.9634\n",
      "Epoch [6/32] - Loss: 0.9483\n",
      "Epoch [7/32] - Loss: 0.9304\n",
      "Epoch [8/32] - Loss: 0.8912\n",
      "Epoch [9/32] - Loss: 0.8507\n",
      "Epoch [10/32] - Loss: 0.8047\n",
      "Epoch [11/32] - Loss: 0.7052\n",
      "Epoch [12/32] - Loss: 0.6207\n",
      "Epoch [13/32] - Loss: 0.4879\n",
      "Epoch [14/32] - Loss: 0.3568\n",
      "Epoch [15/32] - Loss: 0.2534\n",
      "Epoch [16/32] - Loss: 0.2347\n",
      "Epoch [17/32] - Loss: 0.1953\n",
      "Epoch [18/32] - Loss: 0.1233\n",
      "Epoch [19/32] - Loss: 0.0027\n",
      "Epoch [20/32] - Loss: 0.0000\n",
      "Epoch [21/32] - Loss: 0.0000\n",
      "Epoch [22/32] - Loss: 0.0243\n",
      "Epoch [23/32] - Loss: 0.0000\n",
      "Epoch [24/32] - Loss: 0.0000\n",
      "Epoch [25/32] - Loss: 0.0453\n",
      "Epoch [26/32] - Loss: 0.0128\n",
      "Epoch [27/32] - Loss: 0.0000\n",
      "Epoch [28/32] - Loss: 0.0000\n",
      "Epoch [29/32] - Loss: 0.0000\n",
      "Epoch [30/32] - Loss: 0.0000\n",
      "Epoch [31/32] - Loss: 0.0000\n",
      "Epoch [32/32] - Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 32\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for anchor, positive, negative in loader:\n",
    "        anchor = anchor.to(device)\n",
    "        positive = positive.to(device)\n",
    "        negative = negative.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        anchor_out, positive_out, negative_out = model(anchor, positive, negative)\n",
    "\n",
    "        loss = triplet_loss(anchor_out, positive_out, negative_out)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_loss = running_loss / len(loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {avg_loss:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-04T07:36:36.374378700Z",
     "start_time": "2025-07-04T07:36:17.323972600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance: 5.2442\n",
      "Result: Negative (Different class)\n"
     ]
    }
   ],
   "source": [
    "def classify_by_distance(anchor_path, test_path, model, threshold=0.8, device=\"cuda\"):\n",
    "    model = model.to(device)\n",
    "\n",
    "    anchor_img = Image.open(anchor_path).convert(\"RGB\")\n",
    "    test_img = Image.open(test_path).convert(\"RGB\")\n",
    "\n",
    "    anchor_tensor = transform(anchor_img).unsqueeze(0).to(device)\n",
    "    test_tensor = transform(test_img).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        anchor_embed = model(anchor_tensor)\n",
    "        test_embed = model(test_tensor)\n",
    "        dist = F.pairwise_distance(anchor_embed, test_embed).item()\n",
    "\n",
    "    print(f\"Distance: {dist:.4f}\")\n",
    "    if dist < threshold:\n",
    "        return \"Positive (Same class)\"\n",
    "    else:\n",
    "        return \"Negative (Different class)\"\n",
    "\n",
    "result = classify_by_distance(\"triplet_data/anchor/4.jpg\", \"triplet_data/negative/4.jpg\", embedding_net, threshold=1.0)\n",
    "print(\"Result:\", result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-04T07:49:22.283861800Z",
     "start_time": "2025-07-04T07:49:21.510859700Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
